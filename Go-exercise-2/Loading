/*
Tasks and conditions step by step
- The program read unill get two 404 respoonses in a row
- Each request will generate a JSON object as a string
- Use [ and ] instead of comma before the first object
- The result will be a file with a JSON array of metadata objects,
    so we don't need to decode JSON file
- We optionally take a filename from the command line for output
*/
package main

import (
	"bytes"
	"fmt"
	"io"
	"io/ioutil"
	"net/http"
	"os"
)

// coming back from the server; we just dump it out as text
// getOne returns the metadata for one comic by number.

func getOne(i int) []byte {
	url := fmt.Sprintf("https://xkcd.com/%d/info.0.json", i) // the number is inside
	resp, err := http.Get(url)

	if err != nil {
		fmt.Fprintf(os.Stderr, "stopped reading: %s\n", err)
		os.Exit(-1)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		// easter egg: #404 returns HTTP 404 - not found

		fmt.Fprintf(os.Stderr, "skipping %d: got %d\n", i, resp.StatusCode)
		return nil
	}

	body, err := ioutil.ReadAll(resp.Body)

	if err != nil {
		fmt.Fprintf(os.Stderr, "bad body: %s\n", err)
		os.Exit(-1)
	}

	return body
}

func main() {
	var (
		output io.WriteCloser = os.Stdout
		err    error
		cnt    int
		fails  int
		data   []byte
	)

	if len(os.Args) > 1 {
		output, err = os.Create(os.Args[1]) // compare one command line Args

		if err != nil {
			fmt.Fprintln(os.Stderr, err)
			os.Exit(-1)
		}

		defer output.Close()
	}

	// the output will be in the form of a JSON array,
	// so add the brackets before and after

	fmt.Print("[")
	defer fmt.Print("]")

	// stop if we get 2 404s in a row (get passed #404)

	for i := 1; fails < 2; i++ {
		if data = getOne(i); data == nil {
			fails++
			continue
		}
	}

	if cnt > 0 {
		fmt.Fprint(output, ",") // object 1
	}

	_, err = io.Copy(output, bytes.NewBuffer(data))

	if err != nil {
		fmt.Fprintf(os.Stderr, "stopped: %s\n", err)
		os.Exit(-1)
	}

	fails = 0
	cnt++

	fmt.Fprintf(os.Stderr, "read %d comics\n", cnt)
}

/* The program runs over 2MB, therefore it takes much of time to print and run all
the requested downloads. So we have to use cocurrency to to accept
multiple data download at a time.
*/
